{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ¤—Transformersë¡œ íŒŒì¸íŠœë‹ í•œ ëª¨ë¸ Torchserveë¡œ ë°°í¬í•˜ê¸°\n",
    "\n",
    "### ë‹¤ë£¨ëŠ” ë‚´ìš©\n",
    "\n",
    "ì´ ê¸€ì€ ğŸ¤—Transformers ëª¨ë¸ì„ í•™ìŠµí•œ ë’¤ Torchserveë¡œ ë°°í¬í•˜ëŠ” ë°©ë²•ì— ëŒ€í•´ ì†Œê°œí•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ¤—Transformersë¥¼ í™œìš©í•´ Textclassification ëª¨ë¸ í•™ìŠµí•˜ê¸°\n",
    "\n",
    "- ğŸ¤—Transformersì— ìµìˆ™í•˜ì§€ ì•Šì€ ê²½ìš° Huggingfaceì˜ ê¸°ë³¸ ê¸°ëŠ¥ì„ ì†Œê°œí•˜ê³  êµ¬í˜„í•˜ëŠ” ë°©ë²•ì„ ë‹¤ë£¨ëŠ” ~~ì™€ ~~ë¥¼ ì°¸ê³ \n",
    "- ì´ë²ˆì—ëŠ” Distil-bert ëª¨ë¸ì„ Textclassificationë¡œ Fine-tuning í•˜ê² ìŒ. ë°ì´í„° ì„ ì •, ëª¨ë¸ í•™ìŠµì€ Huggingfaceì—ì„œ Tutorialì„ í™œìš©í–ˆìŒ.\n",
    "- ì¶”ê°€ì ì¸ ë‚´ìš© ì´í•´ê°€ í•„ìš”í•œ ê²½ìš° [Huggingfae Fine-tuning turorial](https://huggingface.co/docs/transformers/training) ì˜ˆì œë¥¼ í•¨ê»˜ ì°¸ê³ í•˜ë©´ ì¢‹ìŒ\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### í•™ìŠµ & í‰ê°€ ë°ì´í„° ë§Œë“¤ê¸°\n",
    "\n",
    "- huggingfaceì—ì„œ ì œê³µí•˜ëŠ” `datasets`ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í™œìš©í•´ í•™ìŠµ, í‰ê°€ ë°ì´í„°ë¥¼ ìƒì‚°\n",
    "\n",
    "- dataload_datsetì„ í™œìš©í•˜ë©´ [Huggingface Datasets](https://huggingface.co/datasets)ì„ ì‰½ê²Œ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset yelp_review_full (/Users/yangwoolee/.cache/huggingface/datasets/yelp_review_full/yelp_review_full/1.0.0/e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "739964b0bb0542018f73bf80d4966d78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"yelp_review_full\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 650000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë‚´ë¶€ ë°ì´í„° í™•ì¸ì„ ìœ„í•´ì„œ trainë¥¼ ì„ íƒí•˜ê³  3ê°œì˜ ë°ì´í„°ë§Œ ì¶”ì¶œí•˜ê² ìŠµë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': [4, 1, 3],\n",
       " 'text': [\"dr. goldberg offers everything i look for in a general practitioner.  he's nice and easy to talk to without being patronizing; he's always on time in seeing his patients; he's affiliated with a top-notch hospital (nyu) which my parents have explained to me is very important in case something happens and you need surgery; and you can get referrals to see specialists without having to see him first.  really, what more do you need?  i'm sitting here trying to think of any complaints i have about him, but i'm really drawing a blank.\",\n",
       "  \"Unfortunately, the frustration of being Dr. Goldberg's patient is a repeat of the experience I've had with so many other doctors in NYC -- good doctor, terrible staff.  It seems that his staff simply never answers the phone.  It usually takes 2 hours of repeated calling to get an answer.  Who has time for that or wants to deal with it?  I have run into this problem with many other doctors and I just don't get it.  You have office workers, you have patients with medical needs, why isn't anyone answering the phone?  It's incomprehensible and not work the aggravation.  It's with regret that I feel that I have to give Dr. Goldberg 2 stars.\",\n",
       "  \"Been going to Dr. Goldberg for over 10 years. I think I was one of his 1st patients when he started at MHMG. He's been great over the years and is really all about the big picture. It is because of him, not my now former gyn Dr. Markoff, that I found out I have fibroids. He explores all options with you and is very patient and understanding. He doesn't judge and asks all the right questions. Very thorough and wants to be kept in the loop on every aspect of your medical health and your life.\"]}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][:3]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì´ë²ˆ ì˜ˆì œì—ì„œëŠ” 65000ê°œì˜ í•™ìŠµ ë°ì´í„° ì¤‘ 1000ê°œì˜ ë°ì´í„°ë¥¼ ì„ì˜ë¡œ ì¶”ì¶œí•´ í•™ìŠµì— í™œìš©í•˜ê² ìŠµë‹ˆë‹¤.\n",
    "í‰ê°€ìš© ë°ì´í„°ëŠ” 100ê°œë¥¼ ì¶”ì¶œí•˜ê² ìŠµë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /Users/yangwoolee/.cache/huggingface/datasets/yelp_review_full/yelp_review_full/1.0.0/e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf/cache-a0e621c27d9b360e.arrow\n",
      "Loading cached shuffled indices for dataset at /Users/yangwoolee/.cache/huggingface/datasets/yelp_review_full/yelp_review_full/1.0.0/e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf/cache-61e0da4d9cd46a2c.arrow\n"
     ]
    }
   ],
   "source": [
    "train_dataset = train_dataset = dataset[\"train\"].shuffle(seed=42).select(range(1000))\n",
    "validation_dataset = dataset[\"test\"].shuffle(seed=42).select(range(100))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë°ì´í„° ì¶”ì¶œ ê³¼ì •ì„ ë°˜ë³µí•˜ì§€ ì•Šê¸° ìœ„í•´ csv íŒŒì¼ë¡œ ì €ì¥í•˜ê² ìŠµë‹ˆë‹¤. csvë¡œ ì €ì¥í•˜ê¸° ìœ„í•´ .to_csvë¥¼ í™œìš©í•©ë‹ˆë‹¤. dataset ë‚´ë¶€ëŠ” pandasë¥¼ í™œìš©í•˜ë¯€ë¡œ pandasì˜ .to_csv ë§¤ì„œë“œì™€ ë™ì¼í•œ ì¸ìë¥¼ í™œìš© í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆì œì—ì„œ ì„¤ì •í•œ index=FalseëŠ” csvì— í¬í•¨ëœ indexë¥¼ ì €ì¥í•˜ì§€ ì•ŠëŠ” ê¸°ëŠ¥ì…ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7eea51da8514af2964b65ce443c1798",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating CSV from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c0f3aa8ae16419c958303c29365da9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating CSV from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "956c4eacb6e94da4a3a1143fc28374bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating CSV from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "36382"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.to_csv(\"data/train.csv\", index=False)\n",
    "validation_dataset.to_csv(\"data/validation.csv\", index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ì €ì¥í•œ ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ë°©ë²•ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-1f49b8a4a5164bfe\n",
      "Found cached dataset csv (/Users/yangwoolee/.cache/huggingface/datasets/csv/default-1f49b8a4a5164bfe/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17f14b666d9849719e35281d935f89fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 50\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_dataset(\"csv\", data_files={\"train\": \"data/train.csv\", \"validation\": \"data/test.csv\"})\n",
    "data\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text classification ëª¨ë¸ Fine-tuning\n",
    "\n",
    "- ğŸ¤—Transformersë¥¼ í™œìš©í•˜ë©´ Taskì— í•„ìš”í•œ ëª¨ë¸ êµ¬ì¡°ë¥¼ ì‰½ê²Œ êµ¬í˜„í•  ìˆ˜ ìˆìŒ.\n",
    "\n",
    "- ğŸ¤—TransformersëŠ” BaseModelì„ ê¸°ë°˜ìœ¼ë¡œ í•˜ë˜ output-Layer êµ¬ì¡°ë¥¼ ë³€ê²½í•˜ëŠ” ë°©ë²•ìœ¼ë¡œ ëª¨ë¸ êµ¬ì¡°ë¥¼ ë³€ê²½í•¨.\n",
    "\n",
    "- êµ¬í˜„í•˜ê³ ì í•˜ëŠ” ëª¨ë¸ì€ ë¦¬ë·°ë¥¼ í†µí•´ í‰ì ì„ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸ì´ë¯€ë¡œ ë¦¬ë·°ë¥¼ input ë°ì´í„°ë¡œ ë„£ìœ¼ë©´ í‰ì (1~5)ì„ ë°˜í™˜í•˜ëŠ” êµ¬ì¡°ì—¬ì•¼í•¨.\n",
    "\n",
    "- ì´ëŸ¬í•œ ìœ í˜•ì˜ Taskë¥¼ Text-classificationì´ë¼ í•˜ë©° ğŸ¤—Transformersì˜ sequenceClassification ëª¨ë¸ì„ í†µí•´ êµ¬í˜„í•  ìˆ˜ ìˆìŒ.\n",
    "\n",
    "- í•™ìŠµì— í™œìš©í•œ BaseModelì€ Distil_bertë¥¼ í™œìš©í–ˆìŒ.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-1f49b8a4a5164bfe\n",
      "Found cached dataset csv (/Users/yangwoolee/.cache/huggingface/datasets/csv/default-1f49b8a4a5164bfe/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95ef8d587d8f41ae8dd4a6f03cd668d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import (\n",
    "    DistilBertForSequenceClassification,\n",
    "    DistilBertTokenizer,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    TrainerCallback,\n",
    ")\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "# load data\n",
    "data = load_dataset(\"csv\", data_files={\"train\": \"data/train.csv\", \"validation\": \"data/test.csv\"})\n",
    "\n",
    "train_dataset = data[\"train\"]\n",
    "evaluation_dataset = data[\"validation\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ë°ì´í„° í† í¬ë‚˜ì´ì§•\n",
    "\n",
    "* ëª¨ë“  ë°ì´í„°ì— ëŒ€í•´ í† í¬ë‚˜ì´ì§•ì„ ìˆ˜í–‰í•˜ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44e4c0b5d22340a985d699834c6dde3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e8c890f240543a3baa2a87b4de8c1ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete Tokenizing\n"
     ]
    }
   ],
   "source": [
    "# tokenizing\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "\n",
    "def tokenize_function(item):\n",
    "    return tokenizer(item[\"text\"], padding=\"max_length\", max_length=128, truncation=True)\n",
    "\n",
    "\n",
    "train = train_dataset.map(tokenize_function)\n",
    "evaluation = evaluation_dataset.map(tokenize_function)\n",
    "\n",
    "print(\"complete Tokenizing\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ¤—Transformers ëª¨ë¸ êµ¬ì¡° ì´í•´í•˜ê¸°\n",
    "\n",
    "- sequenceclassifcation êµ¬ì¡°ëŠ” ì—¬ëŸ¬ ì¢…ë¥˜ì˜ taskì— í™œìš©ë  ìˆ˜ ìˆë‹¤. Regression ëª¨ë¸ì„ êµ¬ì„±í•˜ê±°ë‚˜ classification ëª¨ë¸ì„ êµ¬ì„±í•  ë•Œ ì£¼ë¡œ í™œìš©ëœë‹¤.\n",
    "\n",
    "- input data êµ¬ì¡°ì™€, sequenceclassifcationì˜ ì¸ìì¸ num_labelì„ ë³€ê²½í•˜ë©´ sequenceclassifcation êµ¬ì¡° í•˜ë‚˜ë¡œ ë‹¤ì–‘í•œ Task ìˆ˜í–‰ì´ ê°€ëŠ¥í•˜ë‹¤.\n",
    "\n",
    "- sequenceclassifcation êµ¬ì¡°ë¥¼ í™œìš©í•´ êµ¬í˜„ ê°€ëŠ¥í•œ TaskëŠ” Text_classification, SentenceSimilarity, Q&A, Inference ë“±ì´ ìˆë‹¤. ì‚¬ì‹¤ ì´ ì™¸ì—ë„ outputìœ¼ë¡œ regression ë˜ëŠ” classfication ì´ í•„ìš”í•œ ê²½ìš° ëª¨ë‘ ì‚¬ìš©ê°€ëŠ¥í•˜ë‹¤.\n",
    "\n",
    "- input data êµ¬ì¡°ëŠ” ë¬¸ì¥(ë˜ëŠ” ë¬¸ë‹¨)ì„ í•˜ë‚˜ë§Œ ì‚¬ìš©í•˜ëŠ” êµ¬ì¡°ì™€ ë¬¸ì¥(ë˜ëŠ” ë¬¸ë‹¨ì„) ë‘ ê°œ ì‚¬ìš©í•´ ë¹„êµí•˜ëŠ” êµ¬ì¡°ê°€ ìˆë‹¤. Text classificationì˜ ê²½ìš° ì „ìë¥¼ SentenceSimilarity, Q&A, Inferenceì€ í›„ìì˜ êµ¬ì¡°ë¥¼ í•„ìš”ë¡œí•œë‹¤.\n",
    "\n",
    "- num_labelì€ output ìœ í˜•ì„ ê²°ì •í•œë‹¤. num_label = 1ë¡œ ì„¤ì •í•˜ë©´ 0~1ì‚¬ì´ ë²”ìœ„ì˜ Regression ëª¨ë¸ë¡œ í™œìš© ê°€ëŠ¥í•˜ê³  num_labelì„ 2 ì´ìƒìœ¼ë¡œ ì„¤ì •í•˜ë©´ classification ëª¨ë¸ë¡œ í™œìš©ê°€ëŠ¥í•˜ë‹¤.\n",
    "\n",
    "- ğŸ¤—TransformersëŠ” sequenceClassificationì™¸ì—ë„ MaskedLM êµ¬ì¡°, TokenClassification êµ¬ì¡° QuestionAnswering êµ¬ì¡° ë“± ë‹¤ì–‘í•œ êµ¬ì¡°ë¥¼ ì œê³µí•œë‹¤.\n",
    "\n",
    "> Q&A ìœ í˜•ì€ ì„¸ë¶€ì ìœ¼ë¡œ ë‘ ê°€ì§€ê°€ ìˆë‹¤. í•˜ë‚˜ëŠ” Questionì— ëŒ€í•œ ë‹µì„ ìƒì„±í•˜ëŠ” ìœ í˜•, ë‹¤ë¥¸ í•˜ë‚˜ëŠ” Questionì— ëŒ€í•œ ì ì ˆí•œ ë‹µì„ ë³´ê¸°ì—ì„œ ì„ íƒí•˜ëŠ” ìœ í˜•ì´ë‹¤. ì‰½ê²Œ ë§í•´ ì£¼ê´€ì‹, ê°ê´€ì‹ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ë°©ë²•ì´ ìˆë‹¤ê³  ë³´ë©´ëœë‹¤. QuestionAnsweringì€ ì£¼ê´€ì‹ìœ¼ë¡œ outputì„ ìƒì„±í•˜ëŠ” Taskì´ê³  Sequeenceclassificationì€ ê°ê´€ì‹ìœ¼ë¡œ ì£¼ì–´ì§„ ë‹µë³€ì„ ì„ íƒí•˜ëŠ” Taskì´ë‹¤.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequenceclassification Model í•™ìŠµí•˜ê¸°\n",
    "\n",
    "- ğŸ¤—Transformersì˜ ëª¨ë¸ ìœ í˜•ì„ ì´í•´í–ˆìœ¼ë‹ˆ text-classification ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ê³  í•™ìŠµí•˜ëŠ” ë°©ë²•ì— ëŒ€í•´ ì†Œê°œí•˜ê² ë‹¤.\n",
    "\n",
    "- ğŸ¤—Transformersì˜ Trainer APIì— ëŒ€í•œ ì†Œê°œëŠ” ~~~ì—ì„œ ì„¤ëª…í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias', 'pre_classifier.weight', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The following columns in the training set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/Users/yangwoolee/.pyenv/versions/3.9.1/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1000\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 125\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db8ceed66b7d48b28ee4e2b37e9ca9df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10íšŒ ì§„í–‰ ì¤‘ \n",
      "{'loss': 1.6229, 'learning_rate': 4.600000000000001e-05, 'epoch': 0.08}\n",
      "20íšŒ ì§„í–‰ ì¤‘ \n",
      "{'loss': 1.5871, 'learning_rate': 4.2e-05, 'epoch': 0.16}\n",
      "30íšŒ ì§„í–‰ ì¤‘ \n",
      "{'loss': 1.5688, 'learning_rate': 3.8e-05, 'epoch': 0.24}\n",
      "40íšŒ ì§„í–‰ ì¤‘ \n",
      "{'loss': 1.5909, 'learning_rate': 3.4000000000000007e-05, 'epoch': 0.32}\n",
      "50íšŒ ì§„í–‰ ì¤‘ \n",
      "{'loss': 1.4308, 'learning_rate': 3e-05, 'epoch': 0.4}\n",
      "60íšŒ ì§„í–‰ ì¤‘ \n",
      "{'loss': 1.3809, 'learning_rate': 2.6000000000000002e-05, 'epoch': 0.48}\n",
      "70íšŒ ì§„í–‰ ì¤‘ \n",
      "{'loss': 1.3381, 'learning_rate': 2.2000000000000003e-05, 'epoch': 0.56}\n",
      "80íšŒ ì§„í–‰ ì¤‘ \n",
      "{'loss': 1.1999, 'learning_rate': 1.8e-05, 'epoch': 0.64}\n",
      "90íšŒ ì§„í–‰ ì¤‘ \n",
      "{'loss': 1.2068, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.72}\n",
      "100íšŒ ì§„í–‰ ì¤‘ \n",
      "{'loss': 1.2225, 'learning_rate': 1e-05, 'epoch': 0.8}\n",
      "110íšŒ ì§„í–‰ ì¤‘ \n",
      "{'loss': 1.1651, 'learning_rate': 6e-06, 'epoch': 0.88}\n",
      "120íšŒ ì§„í–‰ ì¤‘ \n",
      "{'loss': 1.1877, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125íšŒ ì§„í–‰ ì¤‘ \n",
      "{'train_runtime': 95.6653, 'train_samples_per_second': 10.453, 'train_steps_per_second': 1.307, 'train_loss': 1.3701940231323242, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=125, training_loss=1.3701940231323242, metrics={'train_runtime': 95.6653, 'train_samples_per_second': 10.453, 'train_steps_per_second': 1.307, 'train_loss': 1.3701940231323242, 'epoch': 1.0})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tra_arg = TrainingArguments(\n",
    "    num_train_epochs=1,\n",
    "    output_dir=\"test\",\n",
    "    logging_steps=10,\n",
    "    # evaluation_strategy=\"epoch\",\n",
    ")\n",
    "\n",
    "\n",
    "class myCallback(TrainerCallback):\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        print(f\"{state.global_step}íšŒ ì§„í–‰ ì¤‘ \")\n",
    "\n",
    "\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=5)\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model, args=tra_arg, train_dataset=train, eval_dataset=evaluation, callbacks=[myCallback]\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torchserve ìƒì„±í•˜ê¸°\n",
    "\n",
    "- HuggingfaceëŠ” pytorchë¥¼ ê¸°ë°˜ìœ¼ë¡œ êµ¬ì„±ëê¸° ë•Œë¬¸ì— torchserveë¡œ ë°°í¬í•˜ëŠ” ê²ƒì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.\n",
    "\n",
    "- Huggingface ëª¨ë¸ì„ torchserveë¡œ ë°°í¬í•˜ëŠ” ë°©ë²•ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n",
    "\n",
    "- ëª¨ë¸, tokenizer ì €ì¥, í•¸ë“¤ëŸ¬(Handler) ì œì‘ => MAR file ìƒì„± => torchserveë¡œ ë°°í¬\n",
    "\n",
    "- MAR fileì€ ~~~ë¥¼ í†µí•´ ë§Œë“¤ ìˆ˜ ìˆê³  ì´ë¥¼ ìœ„í•´ì„  Handlerì™€ model, tokenzierê°€ í•„ìš”í•©ë‹ˆë‹¤.\n",
    "\n",
    "- Handler ì„¤ëª…ì— ì•ì„œ trainerë¥¼ í†µí•´ í•™ìŠµí•œ ëª¨ë¸ì„ ì €ì¥í•˜ê³  í† í¬ë‚˜ì´ì €ë„ ì €ì¥í•˜ê² ìŠµë‹ˆë‹¤. ëª¨ë‘ ê°™ì€ ê²½ë¡œì— ì €ì¥í•´ì£¼ì„¸ìš”.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to torch_model\n",
      "Configuration saved in torch_model/config.json\n",
      "Model weights saved in torch_model/pytorch_model.bin\n",
      "tokenizer config file saved in torch_model/tokenizer_config.json\n",
      "Special tokens file saved in torch_model/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('torch_model/tokenizer_config.json',\n",
       " 'torch_model/special_tokens_map.json',\n",
       " 'torch_model/vocab.txt',\n",
       " 'torch_model/added_tokens.json')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.save_model(\"torch_model\")\n",
    "tokenizer.save_pretrained(\"torch_model\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handlerê°€ í•„ìš”í•œ ì´ìœ \n",
    "\n",
    "- ìš°ë¦¬ëŠ” ì§€ê¸ˆ ì „ì²˜ë¦¬ëœ ë°ì´í„° ì…‹ì„ í™œìš©í•´ ëª¨ë¸ì„ í•™ìŠµí–ˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ë°©ì‹ì€ Product í™˜ê²½ì—ì„œëŠ” ì–´ë¦¼ë„ ì—†ëŠ” ì´ì•¼ê¸°ì…ë‹ˆë‹¤. Input Dataë¡œ ìˆ˜ë§ì€ html tagë¡œ ë’¤ë®íŒ ê°’ì´ ë“¤ì–´ì˜¬ ìˆ˜ë„ ìˆê³  Encoding ëœ ê°’ìœ¼ë¡œ ë“¤ì–´ì™€ decodingí•´ì„œ ì‚¬ìš©í•´ì•¼í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "- ë°ì´í„° ì „ì²˜ë¦¬ë§Œ ì‹ ê²½ì“¸ê²Œ ì•„ë‹™ë‹ˆë‹¤. ëª¨ë¸ outputì„ ë°˜í™˜í•  ë•Œ íŠ¹ì • ì–‘ì‹ì— ë§ì¶°ì„œ ë°˜í™˜í•´ì•¼í•œë‹¤ë˜ê°€ Metricì„ ìƒì„±í•œë‹¤ë˜ê°€ í•˜ëŠ” ë°ì´í„° í›„ì²˜ë¦¬ë„ ì‹ ê²½ì¨ì•¼í•©ë‹ˆë‹¤.\n",
    "\n",
    "- ì´ëŸ¬í•œ ë°ì´í„° ì „ì²˜ë¦¬ - ì¶”ë¡  - í›„ì²˜ë¦¬ì˜ íŒŒì´í”„ë¼ì¸ì„ êµ¬ì„±í•˜ëŠ”ë° í•„ìš”í•œ ê¸°ëŠ¥ì„ torchserveì—ì„œëŠ” Handlerë¼ ë¶€ë¦…ë‹ˆë‹¤.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ¤—Transformersë¥¼ ìœ„í•œ Handler\n",
    "\n",
    "- HandlerëŠ” BaseHandler Classë¥¼ ìƒì†ë°›ì•„ ì‘ì„±í•©ë‹ˆë‹¤.\n",
    "\n",
    "- nn.Moduleì„ ì‚¬ìš©í•´ì„œ ëª¨ë¸ì„ ì œì‘í•  ë•Œ forwardë¥¼ ì¬ì‘ì„±í•˜ëŠ” ê²ƒì²˜ëŸ¼, Handler ë˜í•œ ê¸°ë³¸ì ìœ¼ë¡œ BaseHandlerë¥¼ ë¶ˆëŸ¬ì˜¨ ë’¤ preprocess, postprocessë¥¼ êµ¬ì„±í•˜ë©´ ë©ë‹ˆë‹¤.\n",
    "\n",
    "- ì´ë•Œ ğŸ¤—Transformersë¥¼ ì‚¬ìš©í•  ì‹œ transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í™œìš©í•´ ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ë¥¼ ë¶ˆëŸ¬ì™€ì•¼ í•˜ë¯€ë¡œ ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ë¶€ë¶„ì¸ initialize í•¨ìˆ˜ë„ ì¼ë¶€ ìˆ˜ì •í•´ì•¼í•©ë‹ˆë‹¤. ì´ë•Œ ë³€ê²½í•  ì‚¬í•­ì€ ë‘ ê°€ì§€ì…ë‹ˆë‹¤. í•˜ë‚˜ëŠ” `self.model`, ë‹¤ë¥¸ í•˜ë‚˜ëŠ” `self.tokenizer`ì…ë‹ˆë‹¤. ì´ ì™¸ì—ëŠ” BaseHandlerì˜ êµ¬ì¡°ì™€ ë™ì¼í•©ë‹ˆë‹¤.\n",
    "\n",
    "- ì•„ë˜ HandlersëŠ” ê¸°ë³¸ êµ¬ì¡°ì´ë¯€ë¡œ preprocessì™€ postprocessì˜ ë‚´ìš©ì„ ì…ë§›ì— ë§ê²Œ ë³€ê²½í•˜ì‹œë©´ ë©ë‹ˆë‹¤.\n",
    "\n",
    "  > ì£¼ì˜! Torchserveì˜ input dataëŠ” bytearrayë¡œ ë³€í™˜ë˜ì–´ ë“¤ì–´ì˜µë‹ˆë‹¤.\n",
    "  >\n",
    "  > Input dataë¡œ \"Stopped back by Mellow Mushroom with my mate Justin from Brew Bros.\"ì˜ string dataë¥¼ ìš”ì²­í•˜ë©´ ëª¨ë¸ì´ ë°›ëŠ” Input data êµ¬ì¡°ëŠ” `[{'body': bytearray(b'\"Stopped back by Mellow Mushroom with my mate Justin from Brew Bros.\"')}]` ê°€ ë©ë‹ˆë‹¤. ë”°ë¼ì„œ bytearrayë¥¼ decodeí•  ìˆ˜ ìˆê²Œ `txt.decode('utf-8')`ì½”ë“œë¥¼ í¬í•¨í•´ì„œ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "- ëìœ¼ë¡œ Handlerë¥¼ ì‘ë™ì‹œí‚¤ëŠ” Handle í•¨ìˆ˜ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "from ts.torch_handler.base_handler import BaseHandler\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class TransformersClassifierHandler(BaseHandler, ABC):\n",
    "    def __init__(self):\n",
    "        super(TransformersClassifierHandler, self).__init__()\n",
    "        self.initialized = False\n",
    "\n",
    "    def initialize(self, ctx):\n",
    "        self.manifest = ctx.manifest\n",
    "\n",
    "        properties = ctx.system_properties\n",
    "        model_dir = properties.get(\"model_dir\")\n",
    "        self.device = torch.device(\n",
    "            \"cuda:\" + str(properties.get(\"gpu_id\")) if torch.cuda.is_available() else \"cpu\"\n",
    "        )\n",
    "\n",
    "        # Read model serialize/pt file\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "\n",
    "        logger.debug(\"Transformer model from path {0} loaded successfully\".format(model_dir))\n",
    "\n",
    "        # Read the mapping file, index to object name\n",
    "        mapping_file_path = os.path.join(model_dir, \"index_to_name.json\")\n",
    "\n",
    "        if os.path.isfile(mapping_file_path):\n",
    "            with open(mapping_file_path) as f:\n",
    "                self.mapping = json.load(f)\n",
    "        else:\n",
    "            logger.warning(\n",
    "                \"Missing the index_to_name.json file. Inference output will not include class name.\"\n",
    "            )\n",
    "\n",
    "        self.initialized = True\n",
    "\n",
    "    def preprocess(self, data):\n",
    "        \"\"\"Very basic preprocessing code - only tokenizes.\n",
    "        Extend with your own preprocessing steps as needed.\n",
    "        \"\"\"\n",
    "        print(\"------- input data í™•ì¸ --------\")\n",
    "        print(data)\n",
    "        text = data[0].get(\"data\")\n",
    "        if text is None:\n",
    "            text = data[0].get(\"body\")\n",
    "\n",
    "        # inpudataë¡œ bytearrayë¥¼ ë°›ìœ¼ë¯€ë¡œ deoceí•„ìš”\n",
    "        sentences = text.decode(\"utf-8\")\n",
    "\n",
    "        logger.info(\"Received text: '%s'\", sentences)\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(sentences, add_special_tokens=True, return_tensors=\"pt\")\n",
    "        return inputs\n",
    "\n",
    "    def inference(self, inputs):\n",
    "        \"\"\"\n",
    "        Predict the class of a text using a trained transformer model.\n",
    "        \"\"\"\n",
    "        # NOTE: This makes the assumption that your model expects text to be tokenized\n",
    "        # with \"input_ids\" and \"token_type_ids\" - which is true for some popular transformer models, e.g. bert.\n",
    "        # If your transformer model expects different tokenization, adapt this code to suit\n",
    "        # its expected input format.\n",
    "        inputs = inputs.to(self.device)\n",
    "\n",
    "        prediction = self.model(**inputs)[0].argmax().item()\n",
    "        logger.info(\"Model predicted: '%s'\", prediction)\n",
    "\n",
    "        if self.mapping:\n",
    "            prediction = self.mapping[str(prediction)]\n",
    "        return [prediction]\n",
    "\n",
    "    def postprocess(self, inference_output):\n",
    "        # TODO: Add any needed post-processing of the model predictions here\n",
    "        logger.info(\"Model Name: '%s'\", self.model.config._name_or_path)\n",
    "        logger.info(\"Model predicted: '%s'\", inference_output)\n",
    "        return inference_output\n",
    "\n",
    "\n",
    "_service = TransformersClassifierHandler()\n",
    "\n",
    "\n",
    "def handle(data, context):\n",
    "    try:\n",
    "        if not _service.initialized:\n",
    "            _service.initialize(context)\n",
    "\n",
    "        if data is None:\n",
    "            return None\n",
    "\n",
    "        data = _service.preprocess(data)\n",
    "        data = _service.inference(data)\n",
    "        data = _service.postprocess(data)\n",
    "\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        raise e\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAR file ìƒì„±í•˜ê¸°\n",
    "\n",
    "- ì´ì œ Mar fileì„ ìƒì„±í•  ìˆ˜ ìˆëŠ” ì¡°ê±´ì´ ê°–ì¶°ì¡ŒìŠµë‹ˆë‹¤. model, tokenizer, handlerê°€ ë™ì¼í•œ ê²½ë¡œì— ìˆëŠ”ì§€ ë‹¤ì‹œ í•œ ë²ˆ í™•ì¸í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "- Mar ìƒì„±ì€ ì»¤ë§¨ë“œì—ì„œ `torch-model-archiver`ë¥¼ ì‹¤í–‰í•´ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "\n",
    "- Terminalì„ ì¼œì„œ model, tokenizer, handlerê°€ ìˆëŠ” ê²½ë¡œë¡œ ì´ë™í•©ë‹ˆë‹¤. ì•„ë˜ì˜ ëª…ë ¹ì–´ë¥¼ ë³¸ì¸ì´ ì €ì¥í•œ ê²½ë¡œì— ë§ê²Œ ìˆ˜ì •í•´ì£¼ì„¸ìš”.\n",
    "  `--serialized-file=pytorch_model.bin`, `--handler \"./torch_serve_for_kserve.py\"`, `--extra-files \"./bert_model/config.json,./bert_model/vocab.txt\"` ì´ ë¶€ë¶„ì„ ìˆ˜ì •í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "  > Torchserve í™œìš©ì„ ìœ„í•´ `pip install torchserve torch-model-archiver torch-workflow-archiver`ì„ ìš°ì„  ì„¤ì¹˜í•´ì£¼ì„¸ìš”\n",
    "\n",
    "```bash\n",
    "torch-model-archiver --model-name bert-model --version 1.0 --serialized-file ./bert_model/pytorch_model.bin  --handler \"./torch_serve_for_kserve.py\" --extra-files \"./bert_model/config.json,./bert_model/vocab.txt\"\n",
    "```\n",
    "\n",
    "- ê·¸ëŸ¼ í•´ë‹¹ ê²½ë¡œì— bert-model.mar ì´ë¼ëŠ” íŒŒì¼ì´ ìƒˆë¡œ ìƒê¸´ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "- mar Fileì˜ ë‚´ë¶€êµ¬ì¡°ëŠ” argsì— í¬í•¨í•œ íŒŒì¼ + MAR_INF í´ë” ë‚´ë¶€ì— ìˆëŠ” json íŒŒì¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "  ```json\n",
    "  # MAR_INF ë‚´ë¶€ Json ì •ë³´\n",
    "  {\n",
    "    \"createdOn\": \"17/01/2023 18:36:16\",\n",
    "    \"runtime\": \"python\",\n",
    "    \"model\": {\n",
    "      \"modelName\": \"bert-model\",\n",
    "      \"serializedFile\": \"pytorch_model.bin\",\n",
    "      \"handler\": \"torch_serve_for_kserve.py\",\n",
    "      \"modelVersion\": \"1.0\"\n",
    "    },\n",
    "    \"archiverVersion\": \"0.7.0\"\n",
    "  }\n",
    "  ```\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TorchServe ë°°í¬í•˜ê¸°\n",
    "\n",
    "- ì´ì œ ëª¨ë¸ì„ ë°°í¬í•  ì¼ë§Œ ë‚¨ì•˜ìŠµë‹ˆë‹¤. ìš°ì„  model_store í´ë”ë¥¼ ë§Œë“  ë’¤ bert-model.mar íŒŒì¼ì„ ë‚´ë¶€ë¡œ ì´ë™í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "- ë‹¤ìŒì˜ ëª…ë ¹ì–´ë¥¼ ìƒí–‰í•´ ì •ìƒ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸í•´ë³´ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "- `--model-store`ëŠ” í´ë” ê²½ë¡œ, `--models`ì€ `ëª¨ë¸ëª…`ê³¼ MarFileì„ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "\n",
    "- `ëª¨ë¸ëª…`ì€ API Endpointë¡œ í™œìš©ë˜ë¯€ë¡œ ê¸°ì–µí•´ì£¼ì…”ì•¼í•©ë‹ˆë‹¤.\n",
    "\n",
    "  ```bash\n",
    "\n",
    "  torchserve --start --model-store model_store --models bert=bert_model.mar\n",
    "\n",
    "  ```\n",
    "\n",
    "> Error log ì¤‘ empty snapshotìœ¼ë¡œ ëœ¨ëŠ” ê²½ìš° `--no-config-snapshots`ì„ ì¶”ê°€ë¡œ í¬í•¨í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "- ì´ì œ ìƒˆë¡œìš´ Terminalì„ ë„ìš°ê³  APIì— ì ‘ê·¼í•´ë³´ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "- torchserveì—ì„œ ì‚¬ìš©í–ˆë˜ `ëª¨ë¸ëª…`ì„ í™œìš©í•´ ì£¼ì†Œë¥¼ http://127.0.0.1:8080/predictions/`ëª¨ë¸ëª…`ìœ¼ë¡œ ë³€ê²½í•´ì•¼í•©ë‹ˆë‹¤.\n",
    "\n",
    "```bash\n",
    "\n",
    "curl -X POST http://127.0.0.1:8080/predictions/bert -d Stopped back by Mellow Mushroom with my mate Justin from Brew Bros.\n",
    "\n",
    "ê²°ê³¼ :\n",
    "```\n",
    "\n",
    "- Torchserveê°€ ì¼œì§„ í™˜ê²½ì„ ë³´ë©´ Input dataê°€ ì •í™•íˆ ë“¤ì–´ì™”ìŒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TorchServeë¥¼ ì»¨í…Œì´ë„ˆë¡œ ì œì‘í•˜ê¸°\n",
    "\n",
    "* ì´ë²ˆì—” Torchserveë¥¼ í†µí•´ ë°°í¬í•œ ëª¨ë¸ì„ ì»¨í…Œì´ë„ˆë¡œ ì œì‘í•˜ê² ìŠµë‹ˆë‹¤.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KFPë¥¼ í™œìš©í•´ Training PipeLine ë§Œë“¤ê¸°\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### New\n",
    "from functools import partial\n",
    "from kfp.components import create_component_from_func, InputPath, OutputPath\n",
    "\n",
    "\n",
    "@partial(\n",
    "    create_component_from_func,\n",
    "    packages_to_install=[\"pandas\"],\n",
    ")\n",
    "def load_data(\n",
    "    train_path: OutputPath(\"csv\"),\n",
    "    evaluation_path: OutputPath(\"csv\"),\n",
    "):\n",
    "\n",
    "    import pandas as pd\n",
    "\n",
    "    # load data from github\n",
    "    df_train = pd.read_csv(\n",
    "        \"https://raw.github.com/yangoos57/Learning_kubeflow/main/mini_project/data/train.csv\"\n",
    "    )\n",
    "    df_evaluation = pd.read_csv(\n",
    "        \"https://raw.github.com/yangoos57/Learning_kubeflow/main/mini_project/data/validation.csv\"\n",
    "    )\n",
    "\n",
    "    df_train.to_csv(train_path, index=False)\n",
    "    df_evaluation.to_csv(evaluation_path, index=False)\n",
    "\n",
    "    print(\"complete Loading Data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@partial(create_component_from_func, base_image=\"679oose/basepython:1.0\")\n",
    "def train_model(\n",
    "    train_path: InputPath(\"csv\"),\n",
    "    evaluation_path: InputPath(\"csv\"),\n",
    "    model_save_path: OutputPath(\"folder\"),\n",
    "):\n",
    "\n",
    "    from transformers import (\n",
    "        DistilBertForSequenceClassification,\n",
    "        DistilBertTokenizer,\n",
    "        Trainer,\n",
    "        TrainingArguments,\n",
    "        TrainerCallback,\n",
    "    )\n",
    "    from datasets import Dataset\n",
    "\n",
    "    # loading data\n",
    "    train_dataset = Dataset.from_csv(train_path)\n",
    "    evaluation_dataset = Dataset.from_csv(evaluation_path)\n",
    "\n",
    "    # tokenizing\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "    def tokenize_function(item):\n",
    "        return tokenizer(item[\"text\"], padding=\"max_length\", max_length=128, truncation=True)\n",
    "\n",
    "    train = train_dataset.map(tokenize_function)\n",
    "    evaluation = evaluation_dataset.map(tokenize_function)\n",
    "\n",
    "    print(\"complete Tokenizing\")\n",
    "\n",
    "    model = DistilBertForSequenceClassification.from_pretrained(\n",
    "        \"distilbert-base-uncased\", num_labels=len(set(train_dataset[\"label\"]))\n",
    "    )\n",
    "    tra_arg = TrainingArguments(\n",
    "        output_dir=\"test\",\n",
    "        num_train_epochs=1,\n",
    "        logging_steps=5,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        disable_tqdm=True,\n",
    "        save_strategy=\"no\",\n",
    "    )\n",
    "\n",
    "    class myCallback(TrainerCallback):\n",
    "        def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "            print(f\"{state.global_step} Steps \")\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=tra_arg,\n",
    "        train_dataset=train,\n",
    "        eval_dataset=evaluation,\n",
    "        callbacks=[myCallback],\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    trainer.save_model(model_save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfp.dsl import pipeline\n",
    "\n",
    "\n",
    "@pipeline(name=\"NLP_Pipeline\")\n",
    "def NLP_Pipeline():\n",
    "    data = load_data()\n",
    "    train_model(data.outputs[\"train\"], data.outputs[\"evaluation\"])\n",
    "\n",
    "\n",
    "import kfp\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    kfp.compiler.Compiler().compile(NLP_Pipeline, \"NLP_Pipeline_1.2.yaml\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1 (default, Jun 13 2022, 17:35:03) \n[Clang 13.1.6 (clang-1316.0.21.2.5)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b2097164ba635ebffc0e3795dc845ae25b57eedf0c1eb5773ded6aee9fc1b279"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
