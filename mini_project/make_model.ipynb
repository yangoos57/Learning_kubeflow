{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"yelp_review_full\")\n",
    "dataset[\"train\"][100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /Users/yangwoolee/.cache/huggingface/datasets/yelp_review_full/yelp_review_full/1.0.0/e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf/cache-a0e621c27d9b360e.arrow\n",
      "Loading cached shuffled indices for dataset at /Users/yangwoolee/.cache/huggingface/datasets/yelp_review_full/yelp_review_full/1.0.0/e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf/cache-61e0da4d9cd46a2c.arrow\n",
      "Loading cached shuffled indices for dataset at /Users/yangwoolee/.cache/huggingface/datasets/yelp_review_full/yelp_review_full/1.0.0/e8e18e19d7be9e75642fc66b198abadb116f73599ec89a69ba5dd8d1e57ba0bf/cache-61e0da4d9cd46a2c.arrow\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dataset[\"train\"].shuffle(seed=42).select([i for i in list(range(1000))])\n",
    "validation_dataset = dataset[\"test\"].shuffle(seed=42).select([i for i in list(range(100))])\n",
    "test_dataset = dataset[\"test\"].shuffle(seed=42).select([i for i in list(range(50))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7eea51da8514af2964b65ce443c1798",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating CSV from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c0f3aa8ae16419c958303c29365da9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating CSV from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "956c4eacb6e94da4a3a1143fc28374bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating CSV from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "36382"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.to_csv('data/train.csv',index=False)\n",
    "validation_dataset.to_csv('data/validation.csv',index=False)\n",
    "test_dataset.to_csv('data/test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertForTokenClassification, DistilBertTokenizer\n",
    "from datasets import Dataset\n",
    "\n",
    "model = DistilBertForTokenClassification.from_pretrained('distilbert-base-uncased', num_labels=len(set(train_dataset['label'])))\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "\n",
    "train_dataset = Dataset.from_csv('data/train.csv')\n",
    "validation_dataset = Dataset.from_csv('data/validation.csv')\n",
    "\n",
    "def tokenize_function(item) :\n",
    "    return tokenizer(item['text'], padding='max_length', max_length=128,truncation=True)\n",
    "\n",
    "train = train_dataset.map(tokenize_function)\n",
    "validation = validation_dataset.map(tokenize_function)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer\n",
    "\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=len(set(train_dataset['label'])))\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    print('metric')\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "step is not a valid IntervalStrategy, please select one of ['no', 'steps', 'epoch']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;31mValueError\u001b[0m: 'step' is not a valid IntervalStrategy",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/yangwoolee/git_repo/Learning_kubeflow/mini_project/make_model.ipynb ì…€ 7\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yangwoolee/git_repo/Learning_kubeflow/mini_project/make_model.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yangwoolee/git_repo/Learning_kubeflow/mini_project/make_model.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m os\u001b[39m.\u001b[39menviron[\u001b[39m'\u001b[39m\u001b[39mDISABLE_MLFLOW_INTEGRATION\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mTrue\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/yangwoolee/git_repo/Learning_kubeflow/mini_project/make_model.ipynb#W6sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m tra_arg \u001b[39m=\u001b[39m TrainingArguments(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yangwoolee/git_repo/Learning_kubeflow/mini_project/make_model.ipynb#W6sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     per_device_train_batch_size\u001b[39m=\u001b[39;49m\u001b[39m16\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yangwoolee/git_repo/Learning_kubeflow/mini_project/make_model.ipynb#W6sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     per_device_eval_batch_size\u001b[39m=\u001b[39;49m\u001b[39m16\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangwoolee/git_repo/Learning_kubeflow/mini_project/make_model.ipynb#W6sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     eval_steps\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangwoolee/git_repo/Learning_kubeflow/mini_project/make_model.ipynb#W6sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     num_train_epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangwoolee/git_repo/Learning_kubeflow/mini_project/make_model.ipynb#W6sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     output_dir\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtest\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangwoolee/git_repo/Learning_kubeflow/mini_project/make_model.ipynb#W6sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     evaluation_strategy\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mstep\u001b[39;49m\u001b[39m'\u001b[39;49m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangwoolee/git_repo/Learning_kubeflow/mini_project/make_model.ipynb#W6sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangwoolee/git_repo/Learning_kubeflow/mini_project/make_model.ipynb#W6sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangwoolee/git_repo/Learning_kubeflow/mini_project/make_model.ipynb#W6sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     model\u001b[39m=\u001b[39mmodel,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangwoolee/git_repo/Learning_kubeflow/mini_project/make_model.ipynb#W6sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     args\u001b[39m=\u001b[39mtra_arg,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangwoolee/git_repo/Learning_kubeflow/mini_project/make_model.ipynb#W6sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     compute_metrics\u001b[39m=\u001b[39mcompute_metrics\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangwoolee/git_repo/Learning_kubeflow/mini_project/make_model.ipynb#W6sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangwoolee/git_repo/Learning_kubeflow/mini_project/make_model.ipynb#W6sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m trainer\u001b[39m.\u001b[39mtrain()\n",
      "File \u001b[0;32m<string>:101\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, output_dir, overwrite_output_dir, do_train, do_eval, do_predict, evaluation_strategy, prediction_loss_only, per_device_train_batch_size, per_device_eval_batch_size, per_gpu_train_batch_size, per_gpu_eval_batch_size, gradient_accumulation_steps, eval_accumulation_steps, eval_delay, learning_rate, weight_decay, adam_beta1, adam_beta2, adam_epsilon, max_grad_norm, num_train_epochs, max_steps, lr_scheduler_type, warmup_ratio, warmup_steps, log_level, log_level_replica, log_on_each_node, logging_dir, logging_strategy, logging_first_step, logging_steps, logging_nan_inf_filter, save_strategy, save_steps, save_total_limit, save_on_each_node, no_cuda, seed, data_seed, jit_mode_eval, use_ipex, bf16, fp16, fp16_opt_level, half_precision_backend, bf16_full_eval, fp16_full_eval, tf32, local_rank, xpu_backend, tpu_num_cores, tpu_metrics_debug, debug, dataloader_drop_last, eval_steps, dataloader_num_workers, past_index, run_name, disable_tqdm, remove_unused_columns, label_names, load_best_model_at_end, metric_for_best_model, greater_is_better, ignore_data_skip, sharded_ddp, fsdp, fsdp_min_num_params, deepspeed, label_smoothing_factor, optim, adafactor, group_by_length, length_column_name, report_to, ddp_find_unused_parameters, ddp_bucket_cap_mb, dataloader_pin_memory, skip_memory_metrics, use_legacy_prediction_loop, push_to_hub, resume_from_checkpoint, hub_model_id, hub_strategy, hub_token, hub_private_repo, gradient_checkpointing, include_inputs_for_metrics, fp16_backend, push_to_hub_model_id, push_to_hub_organization, push_to_hub_token, mp_parameters, auto_find_batch_size, full_determinism, torchdynamo, ray_scope)\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.1/lib/python3.9/site-packages/transformers/training_args.py:986\u001b[0m, in \u001b[0;36mTrainingArguments.__post_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    983\u001b[0m     \u001b[39m# Go back to the underlying string or we won't be able to instantiate `IntervalStrategy` on it.\u001b[39;00m\n\u001b[1;32m    984\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluation_strategy \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluation_strategy\u001b[39m.\u001b[39mvalue\n\u001b[0;32m--> 986\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluation_strategy \u001b[39m=\u001b[39m IntervalStrategy(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluation_strategy)\n\u001b[1;32m    987\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogging_strategy \u001b[39m=\u001b[39m IntervalStrategy(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogging_strategy)\n\u001b[1;32m    988\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave_strategy \u001b[39m=\u001b[39m IntervalStrategy(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave_strategy)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.1/lib/python3.9/enum.py:315\u001b[0m, in \u001b[0;36mEnumMeta.__call__\u001b[0;34m(cls, value, names, module, qualname, type, start)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[39m\"\"\"Either returns an existing member, or creates a new enum class.\u001b[39;00m\n\u001b[1;32m    291\u001b[0m \n\u001b[1;32m    292\u001b[0m \u001b[39mThis method is used both when an enum class is given a value to match\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    312\u001b[0m \n\u001b[1;32m    313\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    314\u001b[0m \u001b[39mif\u001b[39;00m names \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:  \u001b[39m# simple value lookup\u001b[39;00m\n\u001b[0;32m--> 315\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__new__\u001b[39;49m(\u001b[39mcls\u001b[39;49m, value)\n\u001b[1;32m    316\u001b[0m \u001b[39m# otherwise, functional API: we're creating a new Enum type\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_create_(value, names, module\u001b[39m=\u001b[39mmodule, qualname\u001b[39m=\u001b[39mqualname, \u001b[39mtype\u001b[39m\u001b[39m=\u001b[39m\u001b[39mtype\u001b[39m, start\u001b[39m=\u001b[39mstart)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.1/lib/python3.9/enum.py:618\u001b[0m, in \u001b[0;36mEnum.__new__\u001b[0;34m(cls, value)\u001b[0m\n\u001b[1;32m    613\u001b[0m     exc \u001b[39m=\u001b[39m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    614\u001b[0m             \u001b[39m'\u001b[39m\u001b[39merror in \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m._missing_: returned \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m instead of None or a valid member\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    615\u001b[0m             \u001b[39m%\u001b[39m (\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, result)\n\u001b[1;32m    616\u001b[0m             )\n\u001b[1;32m    617\u001b[0m exc\u001b[39m.\u001b[39m__context__ \u001b[39m=\u001b[39m ve_exc\n\u001b[0;32m--> 618\u001b[0m \u001b[39mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.1/lib/python3.9/enum.py:602\u001b[0m, in \u001b[0;36mEnum.__new__\u001b[0;34m(cls, value)\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    601\u001b[0m     exc \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 602\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_missing_(value)\n\u001b[1;32m    603\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    604\u001b[0m     exc \u001b[39m=\u001b[39m e\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.1/lib/python3.9/site-packages/transformers/utils/generic.py:250\u001b[0m, in \u001b[0;36mExplicitEnum._missing_\u001b[0;34m(cls, value)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    249\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_missing_\u001b[39m(\u001b[39mcls\u001b[39m, value):\n\u001b[0;32m--> 250\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    251\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mvalue\u001b[39m}\u001b[39;00m\u001b[39m is not a valid \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, please select one of \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_value2member_map_\u001b[39m.\u001b[39mkeys())\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    252\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: step is not a valid IntervalStrategy, please select one of ['no', 'steps', 'epoch']"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer,TrainingArguments\n",
    "import os\n",
    "\n",
    "os.environ['DISABLE_MLFLOW_INTEGRATION'] = \"True\"\n",
    "\n",
    "\n",
    "tra_arg = TrainingArguments(\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    eval_steps=10,\n",
    "    num_train_epochs=1,\n",
    "    output_dir='test',\n",
    "    evaluation_strategy='step'\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=tra_arg,\n",
    "    train_dataset=train,\n",
    "    eval_dataset=validation,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b2097164ba635ebffc0e3795dc845ae25b57eedf0c1eb5773ded6aee9fc1b279"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
