apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: test-pipeline-
  annotations: {pipelines.kubeflow.org/kfp_sdk_version: 1.8.18, pipelines.kubeflow.org/pipeline_compilation_time: '2023-01-19T18:33:10.021348',
    pipelines.kubeflow.org/pipeline_spec: '{"name": "test_pipeline"}'}
  labels: {pipelines.kubeflow.org/kfp_sdk_version: 1.8.18}
spec:
  entrypoint: test-pipeline
  templates:
  - name: load-data
    container:
      args: [--train, /tmp/outputs/train/data, --evaluation, /tmp/outputs/evaluation/data]
      command:
      - sh
      - -c
      - (PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location
        'pandas' || PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet
        --no-warn-script-location 'pandas' --user) && "$0" "$@"
      - sh
      - -ec
      - |
        program_path=$(mktemp)
        printf "%s" "$0" > "$program_path"
        python3 -u "$program_path" "$@"
      - |
        def _make_parent_dirs_and_return_path(file_path: str):
            import os
            os.makedirs(os.path.dirname(file_path), exist_ok=True)
            return file_path

        def load_data(
            train_path,
            evaluation_path,
        ):

            import pandas as pd
            print('load_pandas')

            # load data from github
            df_train = pd.read_csv(
                "https://raw.github.com/yangoos57/Learning_kubeflow/main/mini_project/data/train.csv"
            )
            df_evaluation = pd.read_csv(
                "https://raw.github.com/yangoos57/Learning_kubeflow/main/mini_project/data/validation.csv"
            )
            print('Complete_loading_data_to_pandas')

            df_train.to_csv(train_path, index=False)
            df_evaluation.to_csv(evaluation_path, index=False)

            print('complete Loading Data')

        import argparse
        _parser = argparse.ArgumentParser(prog='Load data', description='')
        _parser.add_argument("--train", dest="train_path", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("--evaluation", dest="evaluation_path", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)
        _parsed_args = vars(_parser.parse_args())

        _outputs = load_data(**_parsed_args)
      image: python:3.9
    outputs:
      artifacts:
      - {name: load-data-evaluation, path: /tmp/outputs/evaluation/data}
      - {name: load-data-train, path: /tmp/outputs/train/data}
    metadata:
      labels:
        pipelines.kubeflow.org/kfp_sdk_version: 1.8.18
        pipelines.kubeflow.org/pipeline-sdk-type: kfp
        pipelines.kubeflow.org/enable_caching: "true"
      annotations: {pipelines.kubeflow.org/component_spec: '{"implementation": {"container":
          {"args": ["--train", {"outputPath": "train"}, "--evaluation", {"outputPath":
          "evaluation"}], "command": ["sh", "-c", "(PIP_DISABLE_PIP_VERSION_CHECK=1
          python3 -m pip install --quiet --no-warn-script-location ''pandas'' || PIP_DISABLE_PIP_VERSION_CHECK=1
          python3 -m pip install --quiet --no-warn-script-location ''pandas'' --user)
          && \"$0\" \"$@\"", "sh", "-ec", "program_path=$(mktemp)\nprintf \"%s\" \"$0\"
          > \"$program_path\"\npython3 -u \"$program_path\" \"$@\"\n", "def _make_parent_dirs_and_return_path(file_path:
          str):\n    import os\n    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n    return
          file_path\n\ndef load_data(\n    train_path,\n    evaluation_path,\n):\n\n    import
          pandas as pd\n    print(''load_pandas'')\n\n    # load data from github\n    df_train
          = pd.read_csv(\n        \"https://raw.github.com/yangoos57/Learning_kubeflow/main/mini_project/data/train.csv\"\n    )\n    df_evaluation
          = pd.read_csv(\n        \"https://raw.github.com/yangoos57/Learning_kubeflow/main/mini_project/data/validation.csv\"\n    )\n    print(''Complete_loading_data_to_pandas'')\n\n    df_train.to_csv(train_path,
          index=False)\n    df_evaluation.to_csv(evaluation_path, index=False)\n\n    print(''complete
          Loading Data'')\n\nimport argparse\n_parser = argparse.ArgumentParser(prog=''Load
          data'', description='''')\n_parser.add_argument(\"--train\", dest=\"train_path\",
          type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--evaluation\",
          dest=\"evaluation_path\", type=_make_parent_dirs_and_return_path, required=True,
          default=argparse.SUPPRESS)\n_parsed_args = vars(_parser.parse_args())\n\n_outputs
          = load_data(**_parsed_args)\n"], "image": "python:3.9"}}, "name": "Load
          data", "outputs": [{"name": "train", "type": "csv"}, {"name": "evaluation",
          "type": "csv"}]}', pipelines.kubeflow.org/component_ref: '{}'}
  - name: test-pipeline
    dag:
      tasks:
      - {name: load-data, template: load-data}
  arguments:
    parameters: []
  serviceAccountName: pipeline-runner
